{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j2gOGRIHDG03"
   },
   "source": [
    "## Algorithms Used for Classification\n",
    "1. CART (Classification and Regression Trees)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. CART (Classification and Regression Trees) - DecisionTree Classifier\n",
    "- Sampling Technique - Train/Test Split (80:20)\n",
    "- Classification Metrics - Accuracy\n",
    "- Number of Models - 20 models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load the dataset\n",
    "filename = 'D:/MSU_IIT/4th Year/ITD105/ML Using Different Algorithms/Case Studies/Case Study 1/seattle-weather.csv'\n",
    "dataframe = read_csv(filename)\n",
    "\n",
    "# Use LabelEncoder to encode the 'weather' column\n",
    "label_encoder = LabelEncoder()\n",
    "dataframe['weather'] = label_encoder.fit_transform(dataframe['weather'])\n",
    "\n",
    "# Extract features (X) and target variable (Y)\n",
    "X = dataframe.drop(columns=['weather', 'date'])  # Assuming 'date' is not a useful feature\n",
    "Y = dataframe['weather']\n",
    "\n",
    "# Set the test size and random seed for reproducibility\n",
    "test_size = 0.20\n",
    "random_seed = 7  # You can change this value\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=random_seed)\n",
    "\n",
    "model = DecisionTreeClassifier(\n",
    "    max_depth= 5,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=random_seed\n",
    ")\n",
    "\n",
    "model2 = DecisionTreeClassifier(max_depth=10, min_samples_split=5, min_samples_leaf=2, random_state=random_seed)\n",
    "model3 = DecisionTreeClassifier(max_depth=15, min_samples_split=8, min_samples_leaf=3, random_state=random_seed)\n",
    "model4 = DecisionTreeClassifier(max_depth=20, min_samples_split=10, min_samples_leaf=4, random_state=random_seed)\n",
    "model5 = DecisionTreeClassifier(max_depth=18, min_samples_split=6, min_samples_leaf=2, random_state=random_seed)\n",
    "model6 = DecisionTreeClassifier(max_depth=25, min_samples_split=10, min_samples_leaf=5, random_state=random_seed)\n",
    "model7 = DecisionTreeClassifier(max_depth=12, min_samples_split=7, min_samples_leaf=3, random_state=random_seed)\n",
    "model8 = DecisionTreeClassifier(max_depth=18, min_samples_split=9, min_samples_leaf=4, random_state=random_seed)\n",
    "model9 = DecisionTreeClassifier(max_depth=15, min_samples_split=5, min_samples_leaf=2, random_state=random_seed)\n",
    "model10 = DecisionTreeClassifier(max_depth=20, min_samples_split=8, min_samples_leaf=3, random_state=random_seed)\n",
    "model11 = DecisionTreeClassifier(max_depth=22, min_samples_split=11, min_samples_leaf=5, random_state=random_seed)\n",
    "model12 = DecisionTreeClassifier(max_depth=14, min_samples_split=6, min_samples_leaf=2, random_state=random_seed)\n",
    "model13 = DecisionTreeClassifier(max_depth=17, min_samples_split=8, min_samples_leaf=4, random_state=random_seed)\n",
    "model14 = DecisionTreeClassifier(max_depth=23, min_samples_split=10, min_samples_leaf=5, random_state=random_seed)\n",
    "model15 = DecisionTreeClassifier(max_depth=13, min_samples_split=7, min_samples_leaf=3, random_state=random_seed)\n",
    "model16 = DecisionTreeClassifier(max_depth=19, min_samples_split=9, min_samples_leaf=4, random_state=random_seed)\n",
    "model17 = DecisionTreeClassifier(max_depth=16, min_samples_split=5, min_samples_leaf=2, random_state=random_seed)\n",
    "model18 = DecisionTreeClassifier(max_depth=21, min_samples_split=8, min_samples_leaf=3, random_state=random_seed)\n",
    "model19 = DecisionTreeClassifier(max_depth=24, min_samples_split=11, min_samples_leaf=5, random_state=random_seed)\n",
    "model20 = DecisionTreeClassifier(max_depth=11, min_samples_split=6, min_samples_leaf=2, random_state=random_seed)\n",
    "\n",
    "# Make predictions on the test set and print results for each model\n",
    "for i, clf in enumerate([model, model2, model3, model4, model5, model6, model7, model8, model9, model10,\n",
    "                         model11, model12, model13, model14, model15, model16, model17, model18, model19, model20], 1):\n",
    "    clf.fit(X_train, Y_train)\n",
    "    predictions = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(Y_test, predictions)\n",
    "    print(f\"\\nModel {i}\")\n",
    "    print(\"Accuracy: %.2f%%\" % (accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms Used for Regression\n",
    "8. Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Random Forest\n",
    "- Sampling Technique = K-fold Cross Validation (k=10)\n",
    "- Regression Metrics = MAE\n",
    "- Number of Models - 20 models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Load the dataset\n",
    "filename = 'D:/MSU_IIT/4th Year/ITD105/ML Using Different Algorithms/Case Studies/Case Study 1/Rainfall_data.csv'\n",
    "dataframe = read_csv(filename)\n",
    "\n",
    "# Drop the 'Day' column\n",
    "dataframe = dataframe.drop(columns=['Day'])\n",
    "\n",
    "# Extract features (X) and target variable (Y)\n",
    "X = dataframe.drop(columns=['Precipitation'])  # Features excluding 'Precipitation'\n",
    "Y = dataframe['Precipitation']  # Target variable\n",
    "\n",
    "# Set the test size\n",
    "test_size = 0.20  # Hyperparameter: Fraction of the dataset to use for testing\n",
    "seed = 42\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=test_size, random_state=seed)\n",
    "\n",
    "# Train the data on a Random Forest Regressor with specified hyperparameters\n",
    "model = RandomForestRegressor(\n",
    "    n_estimators=100,      \n",
    "    max_depth=None,         \n",
    "    min_samples_split=2,    \n",
    "    min_samples_leaf=1,     \n",
    "    random_state=seed         \n",
    ")\n",
    "\n",
    "model2 = RandomForestRegressor(n_estimators=120, max_depth=8, min_samples_split=3, min_samples_leaf=1, random_state=seed)\n",
    "model3 = RandomForestRegressor(n_estimators=140, max_depth=12, min_samples_split=5, min_samples_leaf=1, random_state=seed)\n",
    "model4 = RandomForestRegressor(n_estimators=160, max_depth=15, min_samples_split=2, min_samples_leaf=1, random_state=seed)\n",
    "model5 = RandomForestRegressor(n_estimators=180, max_depth=10, min_samples_split=4, min_samples_leaf=1, random_state=seed)\n",
    "model6 = RandomForestRegressor(n_estimators=200, max_depth=18, min_samples_split=3, min_samples_leaf=1, random_state=seed)\n",
    "model7 = RandomForestRegressor(n_estimators=220, max_depth=14, min_samples_split=5, min_samples_leaf=1, random_state=seed)\n",
    "model8 = RandomForestRegressor(n_estimators=240, max_depth=20, min_samples_split=2, min_samples_leaf=1, random_state=seed)\n",
    "model9 = RandomForestRegressor(n_estimators=260, max_depth=16, min_samples_split=4, min_samples_leaf=1, random_state=seed)\n",
    "model10 = RandomForestRegressor(n_estimators=280, max_depth=22, min_samples_split=3, min_samples_leaf=1, random_state=seed)\n",
    "model11 = RandomForestRegressor(n_estimators=300, max_depth=10, min_samples_split=5, min_samples_leaf=1, random_state=seed)\n",
    "model12 = RandomForestRegressor(n_estimators=320, max_depth=24, min_samples_split=2, min_samples_leaf=1, random_state=seed)\n",
    "model13 = RandomForestRegressor(n_estimators=340, max_depth=12, min_samples_split=4, min_samples_leaf=1, random_state=seed)\n",
    "model14 = RandomForestRegressor(n_estimators=360, max_depth=26, min_samples_split=3, min_samples_leaf=1, random_state=seed)\n",
    "model15 = RandomForestRegressor(n_estimators=380, max_depth=14, min_samples_split=5, min_samples_leaf=1, random_state=seed)\n",
    "model16 = RandomForestRegressor(n_estimators=400, max_depth=28, min_samples_split=2, min_samples_leaf=1, random_state=seed)\n",
    "model17 = RandomForestRegressor(n_estimators=420, max_depth=16, min_samples_split=4, min_samples_leaf=1, random_state=seed)\n",
    "model18 = RandomForestRegressor(n_estimators=440, max_depth=30, min_samples_split=3, min_samples_leaf=1, random_state=seed)\n",
    "model19 = RandomForestRegressor(n_estimators=460, max_depth=18, min_samples_split=5, min_samples_leaf=1, random_state=seed)\n",
    "model20 = RandomForestRegressor(n_estimators=480, max_depth=32, min_samples_split=2, min_samples_leaf=1, random_state=seed)\n",
    "\n",
    "\n",
    "for i, rgs in enumerate([model, model2, model3, model4, model5, model6, model7, model8, model9, model10,\n",
    "                         model11, model12, model13, model14, model15, model16, model17, model18, model19, model20], 1):\n",
    "    rgs.fit(X_train, Y_train)\n",
    "    predictions = rgs.predict(X_test)\n",
    "    mae = mean_absolute_error(Y_test, predictions)\n",
    "    print(f\"\\nModel {i}\")\n",
    "    print(\"MAE Score: %.2f\" % (mae))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "How_to_Evaluate_ML_Performance.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
